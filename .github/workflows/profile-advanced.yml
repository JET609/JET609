name: "ü§† Advanced Profile Automations"

on:
  schedule:
    # Runs every day at 18:15 IST (12:45 UTC)
    - cron: "45 12 * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  GITHUB_USERNAME: JET609
  MEDIUM_USERNAME: jayanththomas2004

jobs:
  update-profile:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 1 # Shallow clone for faster checkout

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Update dynamic sections
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GH_USERNAME: ${{ env.GITHUB_USERNAME }}
          MEDIUM_USER: ${{ env.MEDIUM_USERNAME }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import re
          import json
          import datetime
          import random
          import pathlib
          import urllib.request
          import urllib.error
          import xml.etree.ElementTree as ET
          import sys
          import os

          READ_ME = pathlib.Path("README.md")
          
          # Verify README exists
          if not READ_ME.exists():
              print("‚ùå ERROR: README.md not found")
              sys.exit(1)
          
          text = READ_ME.read_text(encoding="utf-8")
          
          # Get configuration from environment
          gh_token = os.environ.get("GH_TOKEN", "")
          gh_username = os.environ.get("GH_USERNAME", "JET609")
          medium_username = os.environ.get("MEDIUM_USER", "jayanththomas2004")

          # ---------- Helpers ----------
          def replace_block(tag, new_content, src):
              """Replace content between comment tags"""
              pattern = rf"<!--{tag}_START-->(.*?)<!--{tag}_END-->"
              repl = f"<!--{tag}_START-->{new_content}<!--{tag}_END-->"
              result = re.sub(pattern, repl, src, flags=re.DOTALL)
              if result == src:
                  print(f"‚ÑπÔ∏è  Info: Tag {tag} not found in README (skipping)")
                  return src
              return result

          def update_last_updated_and_quote(src):
              """Update last updated timestamp and random quote"""
              # IST time (UTC + 5:30) - using timezone-aware datetime
              now_utc = datetime.datetime.now(datetime.timezone.utc)
              ist = now_utc + datetime.timedelta(hours=5, minutes=30)
              last_updated = ist.strftime("%Y-%m-%d %H:%M IST")

              quotes = [
                  "Discipline compounds. Tiny steps, big outcomes.",
                  "Code. Ship. Learn. Repeat.",
                  "Consistency beats motivation.",
                  "Build things that outlive the tutorial.",
                  "Your GitHub is your portfolio. Treat it like one.",
                  "Small progress daily becomes an unfair advantage.",
              ]
              quote = random.choice(quotes)

              def repl(tag, val, s):
                  pattern = rf"<!--{tag}-->(.*?)<!--/{tag}-->"
                  new = f"<!--{tag}-->{val}<!--/{tag}-->"
                  result = re.sub(pattern, new, s, flags=re.DOTALL)
                  if result == s:
                      print(f"‚ÑπÔ∏è  Info: Tag {tag} not found in README (skipping)")
                      return s
                  return result

              src = repl("LAST_UPDATED", last_updated, src)
              src = repl("RANDOM_QUOTE", quote, src)
              return src

          def fetch_medium_posts_feed(username, limit=3):
              """Fetch latest posts from Medium RSS feed"""
              feed_url = f"https://medium.com/feed/@{username}"
              try:
                  req = urllib.request.Request(
                      feed_url,
                      headers={'User-Agent': 'Mozilla/5.0 (GitHub Actions Bot)'}
                  )
                  with urllib.request.urlopen(req, timeout=15) as r:
                      data = r.read()
                  root = ET.fromstring(data)
                  channel = root.find("channel")
                  if channel is None:
                      print("‚ö†Ô∏è  No channel found in Medium feed")
                      return []
                  items = channel.findall("item")[:limit]
                  posts = []
                  for it in items:
                      title = (it.findtext("title") or "").strip()
                      link = (it.findtext("link") or "").strip()
                      if title and link:
                          posts.append((title, link))
                  print(f"‚úÖ Fetched {len(posts)} posts from Medium")
                  return posts
              except urllib.error.URLError as e:
                  print(f"‚ö†Ô∏è  Medium fetch error (network issue, using fallback): {e}")
                  return []
              except Exception as e:
                  print(f"‚ö†Ô∏è  Unexpected error fetching Medium posts: {e}")
                  return []

          def build_blog_md(posts):
              """Build Markdown for blog posts"""
              if not posts:
                  return "\nLoading latest posts...\n"
              lines = ["\n"]
              for title, link in posts:
                  lines.append(f"- [{title}]({link})")
              lines.append("\n")
              return "\n".join(lines)

          def fetch_top_repos(user, token, limit=4):
              """Fetch top repositories from GitHub API"""
              try:
                  url = f"https://api.github.com/users/{user}/repos?per_page=100&sort=updated"
                  headers = {'User-Agent': 'Mozilla/5.0 (GitHub Actions Bot)'}
                  
                  # Add authentication if token is available (increases rate limit to 5000/hr)
                  if token:
                      headers['Authorization'] = f'Bearer {token}'
                  
                  req = urllib.request.Request(url, headers=headers)
                  with urllib.request.urlopen(req, timeout=15) as r:
                      repos = json.load(r)
              except urllib.error.URLError as e:
                  print(f"‚ö†Ô∏è  GitHub API error (network issue, using fallback): {e}")
                  return []
              except Exception as e:
                  print(f"‚ö†Ô∏è  Unexpected error fetching repos: {e}")
                  return []

              # Filter out profile repo and test repos
              ignore = {user, f"{user}.github.io", "JET609"}
              clean = [
                  r for r in repos
                  if not r.get("fork")
                  and r.get("name") not in ignore
                  and not r.get("name", "").lower().startswith("test")
              ]

              # Sort by stars + recent activity
              clean.sort(key=lambda r: (r.get("stargazers_count", 0), r.get("pushed_at") or ""), reverse=True)
              filtered = clean[:limit]
              print(f"‚úÖ Fetched {len(filtered)} top repositories")
              return filtered

          def build_projects_md(repos):
              """Build Markdown for projects"""
              if not repos:
                  return "\nHighlighting key projects soon...\n"
              lines = ["\n"]
              for r in repos:
                  name = r["name"]
                  desc = (r.get("description") or "No description yet.").strip()
                  stars = r.get("stargazers_count", 0)
                  lang = r.get("language") or "Tech"
                  url = r.get("html_url")
                  lines.append(
                      f"- [{name}]({url}) ‚Äî {desc} "
                      f"¬∑ ‚≠ê {stars} ¬∑ *{lang}*"
                  )
              lines.append("\n")
              return "\n".join(lines)

          # ---------- Apply updates ----------
          print("üîÑ Starting README update...")
          updated = text

          # 1) Last updated + random quote
          print("üìÖ Updating timestamp and quote...")
          updated = update_last_updated_and_quote(updated)

          # 2) Blog posts from Medium
          print(f"üìù Fetching Medium posts for @{medium_username}...")
          posts = fetch_medium_posts_feed(medium_username)
          blog_md = build_blog_md(posts)
          updated = replace_block("BLOG", blog_md, updated)

          # 3) Auto top projects from GitHub (optional section)
          print(f"üöÄ Fetching top repositories for {gh_username}...")
          repos = fetch_top_repos(gh_username, gh_token)
          proj_md = build_projects_md(repos)
          updated = replace_block("PROJECTS", proj_md, updated)

          # Write changes
          if updated != text:
              READ_ME.write_text(updated, encoding="utf-8")
              print("‚úÖ README.md updated successfully")
          else:
              print("‚ÑπÔ∏è  No changes made to README.md")
          PYTHON_SCRIPT

      - name: Commit & push if changed
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          if [[ -n "$(git status --porcelain)" ]]; then
            git add README.md
            git commit -m "chore: üß† auto-update profile sections $(date -u +"%Y-%m-%d")" || exit 0
            git push
            echo "‚úÖ Changes committed and pushed successfully"
          else
            echo "‚ÑπÔ∏è  No changes to commit"
          fi
